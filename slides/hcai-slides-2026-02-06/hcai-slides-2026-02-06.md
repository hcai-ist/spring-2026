---
pagetitle: IST 597 (HCAI) — 2026-02-06
date-meta: 2026-02-06
author-meta: Saeed Abdullah (saeed@psu.edu)
revealjs-url: ../../common/pandoc-reveal.js/reveal.js
theme: teaching-dark
slideNumber: true
hash: true
hashOneBasedIndex: true
highlightjs: true
highlightjs-theme: dracula
---

# How does Penn State spend your tuition?

#### Using LLM for data extraction

---

## Recap from last class

---

## We will focus on text based prompting

::::{.columns style="justify-content: center; align-items: center; align-items: center;"}
:::{.column style="background-color: #ffff; max-width:75%;"}
![](./media/text-prompting.png){alt="A tree showing categories of core prompt techniques. It includes 'text based techniques' as the root element and 'multilingual techniques' and 'multimodal techniques' as the children elements"}
:::
::::


:::{.t-ref}
[The Prompt Report: A Systematic Survey of Prompting Techniques](http://arxiv.org/abs/2406.06608)
:::

---

## Key resources

* [The Prompt Report: A Systematic Survey of Prompting Techniques](http://arxiv.org/abs/2406.06608)
* [Prompt engineering using Instructor](https://python.useinstructor.com/prompting/)

---


## Some definitions first

---


### What's a prompt?

* "A prompt is an input to a Generative AI model, that is used to guide its output"
* "Prompts may consist of text, image, sound, or other media"

---

## Prompting is for [in-context learning (ICL)]{.t-clover}

* “the ability of GenAIs to learn skills and tasks by providing them with exemplars and or relevant instructions within the prompt”

* [**No**]{.t-salmon} retraining of models ([**no**]{.t-salmon} model weight updates)

---




### What’s a prompt template?
* "A prompt template is a function that contains one or more variables which will be replaced by some media (usually text) to create a prompt."
* "a prompt template becomes a prompt when input is inserted into it.”

---

### What’s a prompt template?

* "a prompt template becomes a prompt when input is inserted into it.”

* Template: "Write a poem about {{TOPIC}}”
    + Prompt: "Write a poem about HCAI"


---


#### Can have multiple variables

* "Write a {{POEM FORM}} about {{TOPIC}}”
    + Write a sonnet about HCAI

---


### Prompt chain

* “two or more prompt templates used in succession”
* “The output of the prompt generated by the first prompt template is used to parameterize the second template, continuing until all templates are exhausted”

---

## Prompt engineering

* “the iterative process of developing a prompt by modifying or changing the prompting technique that you are using”

---



### Prompt components
* Directives
* Examples/Shots/Exemplars
* Output Formatting
* Style
* Role
* Context
    + Additional Information

---

#### Directives — what's to be done?

* Explicit
    + “Write a poem”
* Implicit
    + "Good morning: buen día
    + Good night: "

---

#### Examples/Exemplars/Shots
Demonstrations that guide the GenAI to accomplish a task

---

#### 1-shot
+ "Good morning: buen día
+ Good night: "

---


#### Few-shot

```
2+2: four
4+5: nine
8+0:
```

How many shots?

---

## Text based prompting techniques

---


### Text based prompting techniques — [lots]{.t-salmon} of options!
::::{.columns style="justify-content: center; align-items: center; align-items: center;"}
:::{.column style="background-color: #ffff; max-width:35%;"}
![](./media/prompting-strategy.png){alt=""}
:::
::::

:::{.t-ref}
[The Prompt Report: A Systematic Survey of Prompting Techniques](http://arxiv.org/abs/2406.06608)
:::

---


## Text based prompting techniques
* Zero-shot
* Few-shot
* Chain of thought (CoT)

---


## Meta prompting

::::{.columns style="justify-content: center; align-items: center; align-items: center;"}
:::{.column style="background-color: #ffff; max-width:35%;"}
![](./media/meta-prompting.png){alt=""}
:::
::::

:::{.t-ref}
[Prompt Engineering a Prompt Engineer](https://arxiv.org/pdf/2311.05661)
:::


---

## Today
* Output formatting
* Data extraction

---

## Output formatting
* We often want structured output

* When you are [**using LLMs as a pipeline or infrastructure**]{.t-salmon} for further processing, you want [**consistency**]{.t-clover}

---

### Free form text output is not fun to parse 

::::{.columns style="justify-content: center; align-items: center; align-items: center;"}
:::{.column style="background-color: #ffff; max-width:45%;"}
![](./media/free-form-response.png){alt=""}
:::
::::


---


### We want structured output (using [Instructor](https://python.useinstructor.com/))

```python{data-line-numbers="1"}
import instructor

class Response(BaseModel):
    message: str

r = client.responses.create(
    input="Write a haiku about IST 597 (HCAI)",
    response_model=Response,
)
```

---

### Define the structure of response from LLMs

```python{data-line-numbers="3-4,8"}
import instructor

class Response(BaseModel):
    message: str

r = client.responses.create(
    input="Write a haiku about IST 597 (HCAI)",
    response_model=Response,
)
```

`response_model`: expected structure

---

### Different data types

```python
class User(BaseModel):
    name: str
    age: int
```

:::{.t-ref}
[Understanding Response Models](https://python.useinstructor.com/learning/getting_started/response_models/)
:::

---

### What data type should we use for financial data?

```python{data-line-numbers="2"}
class BudgetAnswer(BaseModel):
    amount: float
```

:::{.t-ref}
[Understanding Response Models](https://python.useinstructor.com/learning/getting_started/response_models/)
:::

---

## How does Penn State spend your tuition?

---

### Goal today
* Bridging LLM and external knowledge sources
* Integrate data from different source formats
    - html, markdown, pdf,
* Using LLM for financial statement analysis
    + Exploring its [**strength**]{.t-clover} and [**weakness**]{.t-salmon}

---

## How does Penn State spend your tuition?
* Data
    + [Budget Allocations](https://budgetandfinance.psu.edu/budget-allocations)
    + [Right To Know Law Report](https://budgetandfinance.psu.edu/public-reports)
    + Data available in our [class github repo](https://github.com/hcai-ist/activity-spring-2026/tree/main/data/data-activity-03)

---

### Class activity

* [Activity 03](https://github.com/hcai-ist/activity-spring-2026/blob/main/activity-03.ipynb)

---

### Ask LLM to use an external knowledge source directly
* “Analyze the document at the given URL and answer the query”
* Did it work?

---

### Alternative approach

* Extract data from external source and integrate in the prompt

* I converted [the web page](https://budgetandfinance.psu.edu/budget-allocations) into [markdown table](https://github.com/hcai-ist/activity-spring-2026/tree/main/data/data-activity-03)

* We can integrate the markdown data into the prompt

---

### Class activity
How much money is allocated for Information Sciences & Technology in FY28?

---

### Todo

Which UP colleges have the highest positive and negative percentage changes in 2027 and 2028?

---

### Todo

* Analyze the allocation for other units
    + Add data from: Commonwealth Campuses
        + Click on 'Raw' for [markdown format](https://raw.githubusercontent.com/hcai-ist/activity-spring-2026/refs/heads/main/data/data-activity-03/budget-all-tables.md)
    + Come up with 3 questions to answer
    + Complete code to answer these questions
    + Check answers for accuracy

---

### What if our data is in pdf?

* [Right To Know Law Reports](https://budgetandfinance.psu.edu/public-reports#:~:text=Right%20To%20Know%20Law%20Report)

---

### 3 options for handling pdf data

* Do it by yourself
    * Extract the text data from the pdf using a third-party package
    + `pymupdf` converts [**pdf to markdown**]{.t-salmon}

* Use the vision API to convert image to text

* Use the [file search](https://platform.openai.com/docs/guides/tools-file-search) API

---

### Using data in pdf format as a knowledge source

* Extract textual data from the pdf using an external library `pymupdf4llm`
* Use the textual data as part of the prompt

---

### Using `pymupdf4llm` for extracting pdf data

```python
## We will extract page 45–46
# Note that `pymupdf4llm` uses 0-based index for pages
highest_paid = pymupdf4llm.to_markdown("right_to_know_2024.pdf", pages=[44, 45])
```

:::{.t-ref}
[pymupdf4llm documentation](https://pymupdf.readthedocs.io/en/latest/pymupdf4llm/api.html#pymupdf4llm-api:~:text=pages%20%28list%29)
:::

---


### Todo

* How much did the CEO of Penn State Health earn?
* What was the biggest source of PSU revenue?
* How much did Penn State spend on advertising and promotion?
* How much did IST Dean earn?

---

### Processing the whole pdf

```python
highest_paid = pymupdf4llm.to_markdown("right_to_know_2024.pdf")
```

Omitting `pages` argument will process the whole pdf. What happens if you try it?

:::{.t-ref}
[pymupdf4llm documentation](https://pymupdf.readthedocs.io/en/latest/pymupdf4llm/api.html#pymupdf4llm-api:~:text=pages%20%28list%29)
:::

---

### Processing the whole pdf

```python
highest_paid = pymupdf4llm.to_markdown("right_to_know_2024.pdf")
```

This pdf is too large to include in the prompt. Might work for a smaller pdf

:::{.t-ref}
[pymupdf4llm documentation](https://pymupdf.readthedocs.io/en/latest/pymupdf4llm/api.html#pymupdf4llm-api:~:text=pages%20%28list%29)
:::

---




